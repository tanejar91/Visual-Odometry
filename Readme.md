## Visual-Odometry
This repository contians the code and results to estimate an autonomous vehicle trajectory by images taken with a monocular camera 
set up on the vehicle. Data is taken from the Coursera course 'Visual Perception for Self-Driving Cars'.

## Procedure
1. Generate keypoints and descriptors for every image in the dataset. ORB is used for feature detection and descriptor generation.
Code for SURF is also provided(commented), as SURF is not available for python 3.6 in Windows.
2. Match features between subsequent pairs of images. Use Lowe's ratio test to filter the mateches.
3. Estimate camera motion from subsequent images. Camera motion here means rotation and translation of the camera. Function 
estimate_motion_EssentialMat is used for this task. This task is achieved by Essential Matrix Decomposition. Essential matrix can be 
found using "cv2.findEssentialMat()"; this function takes matched keypoints in subsequent pair of images and camera matrix as arguments.
4. Estimate trajectory using rotation matrix and translation vector obtained from previous steps. For calculating trajectory, translation matrix  must be converted to a coordinate system whose origin is at the initial position of the camera. To do this, at each step, inverse transormation matrix shall be constructed from rotation matrix and translation vector and shall be left multiplied by the matrix obtained in previous step.

Transformation Matrix at step k: 

![equation](https://latex.codecogs.com/gif.latex?T_%7Bk%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20rmat_%7Bk%2Ck-1%7D%20%26%20tvec_%7Bk%2Ck-1%7D%5C%5C%200%20%26%201%20%5Cend%7Bbmatrix%7D)

where:

![equation](https://latex.codecogs.com/gif.latex?rmat%20%5Cin%20%5Cmathbb%7BR%7D%20%5E%7B3x3%7D) is rotation matrix obtained in step 3

![equation](https://latex.codecogs.com/gif.latex?tvec%20%5Cin%20%5Cmathbb%7BR%7D%20%5E%7B3x1%7D) is traslation vector from step 3

Let  ![equation](https://latex.codecogs.com/gif.latex?%5Cquad%20C_%7B0%7D%20%5Cquad)   be the initital camera pose which is 4x4 identity matrix.
Camera pose at step step k can be constructed using all the transfomations upto step k-1 using:

![equation](https://latex.codecogs.com/gif.latex?%5Cquad%20C_%7Bk%7D%20%3D%20C_%7Bk-1%7DT_%7Bk%7D%5E%7B-1%7D)

The poistion of camera at step k, given by the first 3 elements of last row of ![equation](https://latex.codecogs.com/gif.latex?%5Cquad%20C_%7Bk%7D).

Trajectory is generated by concatenating camera position at each step.


## Code
 To run download/clone repository and run Visual_Odometry.py
 
## Outputs
Outputs are shown through images.

matched features between image 50 and 51.png - Matched features between a chosen pair of images

Camera movement between images.png - Motion of camera in terms of change in keypoints location between a subsequent pair of images

trajectory.png -  trajectory generated
